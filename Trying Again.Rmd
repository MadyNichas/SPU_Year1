---
title: "Trying Again"
author: "Nichas, Mady"
date: "2022-10-31"
output: html_document
---
 
```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
```
(measure changes across time or each research participant is assessed in multiple conditions)

Mixed methods study (qualitative and quantitative) 
Evaluating the effectiveness of an intervention with participants $(N = 8)$ who experienced transphobic episodes
Focus groups used qualitative methods to summarize emergent themes from the program 
(identity affirmation, self-acceptance, group as support) 

Using a one-way, repeated measures ANOVA to measure of change in resilience from pre, post, and three-month followup.
The DV (assessed at each wave) was a 14-item resilience scale. Items were assessed on a 7-point scale ranging from *strongly disagree* to *strongly agree* with higher scores indicating higher levels of resilience. An example items was, "I usually manage one way or another."

Eight participants participated in the intervention. The mean age was 28.5 years $(*SD* = 5.85)$. 

Simulate data: 8 participants each participated in 3 waves (pre, post, followup)
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
set.seed(2022)
#gives me 8 numbers, assigning each number 3 consecutive spots, in sequence
ID<-factor(c(rep(seq(1,8),each=3)))
#gives me a column of 24 numbers with the specified Ms and SD
Resilience<-rnorm(24,mean=c(5.7,6.21,6.26),sd=c(.88,.79,.37)) 
#repeats pre, post, follow-up once each, 8 times
Wave<-rep(c("Pre","Post", "FollowUp"),each=1,8) 
Amodeo_long<-data.frame(ID, Wave, Resilience)
```

Structure of our variables
ID should be a factor
Resilience to be numeric
Wave to be an ordered factor (Pre, Post, FollowUp)

```{r}
str(Amodeo_long)
```
Wave needs to be changed an ordered factor
R's default is to order factors alphabetically- levels command to identify preferred order

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
Amodeo_long$Wave <- factor(Amodeo_long$Wave, levels = c("Pre", "Post", "FollowUp"))
```

Check the structure again
```{r}
str(Amodeo_long)
```

#Time to reorient the data to wide
#We need to reformat the data (from long/*person-period*) so that a participant's 3 data points will be in the same row wide/*person level*
# *data.table* and *reshape2*- creating a new df oriented wide

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}

Amodeo_wide <- reshape2::dcast(data = Amodeo_long, formula =ID~Wave, value.var = "Resilience")

str(Amodeo_wide)
Amodeo_wide$ID <- factor(Amodeo_wide$ID)
```


As we work the problem we will switch between long and wide formats.
...starting with the long form
```{r}
str(Amodeo_long)
```
#In the following output, note the order of presentation of the grouping variable (i.e., FollowUp, Post, Pre). Even though we have ordered our factor so that "Pre" is first, the *describeBy()* function seems to be ordering them alphabetically.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
psych::describeBy(Amodeo_long$Resilience, Wave, mat = TRUE, data = Amodeo_long, digits = 3)

```

Another view (if we use the wide file).

```{r }
psych::describe(Amodeo_wide)
```
Resilience increases from pre to post, then declines a bit. 
Statistically significant differences between the means and over time 
One-way repeated measures ANOVA

Box Plot!

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
boxplot (Resilience ~ Wave, data = Amodeo_long, xlab = "Wave", ylab = "Resilience", n.label = TRUE)
```

# Testing Assumptions for ANOVA

Checkin for outliers with the boxplot
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
#Note that we are creating an object (bxp) from our work. 
#This script creates the basic boxplot, we will add to it (by using the object) later.
bxp <- ggpubr::ggboxplot(Amodeo_long, x = "Wave", y = "Resilience", add = "point", xlab = "Assessment Wave", ylab = "Self-Perception of Resilience")
bxp
```
 *rstatix* to identify outliers
```{r }
Amodeo_long %>%
  group_by(Wave)%>%
  rstatix::identify_outliers(Resilience)

```

The output, "0 rows" indicates there are no outliers, consistent with  boxplots

#Assessing normality 

Skew & Kurtosis

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
psych::describeBy(Resilience ~ Wave, mat=TRUE, data = Amodeo_long)
```
Below the threshold of concern for both

We can use the Shapiro-Wilk test to check for normality 
*p* < .05, it indicates that the distribution is statistically significantly different from a normal curve
Group the DV by wave so that we can test normality for each cell in the model

```{r }
Amodeo_long %>%
  group_by(Wave) %>%
  rstatix::shapiro_test(Resilience)
```

The *p* value is > .05 for each of the times. We have not violated the assumption of normality


Shapiro-Wilk is sensitive to sample size and Q-Q plot can be a double check

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
ggpubr::ggqqplot(Amodeo_long, "Resilience", facet.by = "Wave")
```


Check the structure
```{r }
str(Amodeo_long)
```
Resilience is num, wave has 3 levels

#Omnibus ANOVA and Mauchly's Test
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
RM_AOV <- rstatix::anova_test(data = Amodeo_long, dv = Resilience, wid = ID, within = Wave)
RM_AOV
```
 $F(2,14) = 3.91, p = 0.045, \eta^2 = 0.203$ (Medium)

Sphericity: we did not violate the sphericity assumption: $W = 0.566, p = .182$


Follow-up with post hoc, pairwise, comparisons
Note that when I am calculating these pairwise *t* tests
Object (named "pwc") so we can make a Figure & APA tables

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
pwc <- Amodeo_long %>%
    rstatix::pairwise_t_test(Resilience ~ Wave, paired = TRUE, p.adjust.method = "bonferroni")
pwc
```
Statistically significant omnibus test
No statistically significant results in an of the posthoc pairwise comparisons

Combine information from the object we created ("bxp") 
with the object we saved from the posthoc pairwise comparisons ("pwc) 
to enhance our boxplot with the *F* string and indications of pairwise significant 
(or, in our case, non-significance). 
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
pwc <- pwc %>% rstatix::add_xy_position(x = "Wave")
bxp + 
  ggpubr::stat_pvalue_manual(pwc) +
  labs(
    subtitle = rstatix::get_test_label(RM_AOV, detailed = TRUE),
    caption = rstatix:: get_pwc_label(pwc)
  )
```

#mady reminders
#Assumptions for repeated measures ANOVA: no outliers, normality, and sphericity
*rstatix::identify_outliers()* function indicated no outliers

A mixed methods study (qualitative and quantitative) was conducted evaluating the effectiveness of an intervention with participants $(N = 8)$ who experienced transphobic episodes. We used a one-way, repeated measures ANOVA to measure of change in resilience from pre, post, and three-month followup.The DV (assessed at each wave) was a 14-item resilience scale. Items were assessed on a 7-point scale ranging from *strongly disagree* to *strongly agree* with higher scores indicating higher levels of resilience. An example items was, "I usually manage one way or another." We simulated the data, checked for proper structure, and evaluated for assumptions.
No missingness allowed, so we needed 8 participants each participated in 3 waves (pre, post, followup). We tested for skew and kurtosis (at all assessment times) fell below cautionary ranges (3 and 8 respectively).  Then a Shapiro-Wilk tests resulted in a  non-significant p value at all times (waves). To test for assumption of sphericity, we used Mauchley's test ($W = 0.566, p = .182$) and found the results to be not significant (sphericity assumption not violated)
We moved on to the Omnibus ANOVA and found a significant p: $F(2,14) = 3.91, p = 0.045, \eta^2 = 0.203$(Medium effect). Pairwise comparison follow up using a bonferroni to control for Type I error, indicated no statistically significant differences between any of the pairs Pre versus post, $*t* = -2.15, *p*= .069$, Pre versus follow-up, $*t* = -2.00, *p* = .068$, Post versus follow-up, $*t* = 1.059, *p* = .325$ 
Our power analysis indicated we had a 16% chance of finding a statistically significant effect if it existed and we would need 50 individuals in order to feel confident in our ability to get a statistically significant result if it existed.


(Small sample size likely contributed to a Type II error)

#Power Analysis
Change our $\eta^2$ to Cohen's *f*

```{r message=FALSE, warning=FALSE}
effectsize::eta2_to_f(.203) 
```

```{r message=FALSE, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=70)}
WebPower::wp.rmanova(n=8, ng=1, nm=3, f = .5047, nscor = .689, alpha = .05, power = NULL, type = 1)
```
Had a 16% chance of finding a statistically significant effect if it existed

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
WebPower::wp.rmanova(n=NULL, ng=1, nm=3, f = .5047, nscor = .689, alpha = .05, power = .80, type = 1)
```
With these new values, we learn that we would need 50 individuals in order to feel confident in our ability to get a statistically significant result if it existed.